{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQB5JHEinNY8"
   },
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zNuAt5Q5kWH5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class HMM(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Hidden Markov Model with discrete observations.\n",
    "  \"\"\"\n",
    "  def __init__(self, M, N):\n",
    "    super(HMM, self).__init__()\n",
    "    self.M = M # number of possible observations\n",
    "    self.N = N # number of states\n",
    "\n",
    "    # A\n",
    "    self.transition_model = TransitionModel(self.N)\n",
    "\n",
    "    # b(x_t)\n",
    "    self.emission_model = EmissionModel(self.N,self.M)\n",
    "\n",
    "    # pi\n",
    "    self.unnormalized_state_priors = torch.nn.Parameter(torch.randn(self.N))\n",
    "\n",
    "    # use the GPU\n",
    "    self.is_cuda = torch.cuda.is_available()\n",
    "    if self.is_cuda: self.cuda()\n",
    "\n",
    "class TransitionModel(torch.nn.Module):\n",
    "  def __init__(self, N):\n",
    "    super(TransitionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.unnormalized_transition_matrix = torch.nn.Parameter(torch.randn(N,N))\n",
    "\n",
    "class EmissionModel(torch.nn.Module):\n",
    "  def __init__(self, N, M):\n",
    "    super(EmissionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.M = M\n",
    "    self.unnormalized_emission_matrix = torch.nn.Parameter(torch.randn(N,M))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QVvKf9NqlFDS"
   },
   "outputs": [],
   "source": [
    "def sample(self, T=10):\n",
    "  state_priors = torch.nn.functional.softmax(self.unnormalized_state_priors, dim=0)\n",
    "  transition_matrix = torch.nn.functional.softmax(self.transition_model.unnormalized_transition_matrix, dim=0)\n",
    "  emission_matrix = torch.nn.functional.softmax(self.emission_model.unnormalized_emission_matrix, dim=1)\n",
    "\n",
    "  # sample initial state\n",
    "  z_t = torch.distributions.categorical.Categorical(state_priors).sample().item()\n",
    "  z = []; x = []\n",
    "  z.append(z_t)\n",
    "  for t in range(0,T):\n",
    "    # sample emission\n",
    "    x_t = torch.distributions.categorical.Categorical(emission_matrix[z_t]).sample().item()\n",
    "    x.append(x_t)\n",
    "\n",
    "    # sample transition\n",
    "    z_t = torch.distributions.categorical.Categorical(transition_matrix[:,z_t]).sample().item()\n",
    "    if t < T-1: z.append(z_t)\n",
    "\n",
    "  return x, z\n",
    "\n",
    "# Add the sampling method to our HMM class\n",
    "HMM.sample = sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMMhqyo1lPrs",
    "outputId": "78f0cb29-0d7f-4f98-e9b2-12793fd6e5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State priors: tensor([0.6225, 0.3775])\n",
      "Emission matrix: tensor([[0.0000, 0.1184, 0.0164, 0.0428, 0.0000, 0.0585, 0.0393, 0.0118, 0.0000,\n",
      "         0.0296, 0.0076, 0.0719, 0.0089, 0.0961, 0.0000, 0.0843, 0.0967, 0.0098,\n",
      "         0.0163, 0.0377, 0.0000, 0.0815, 0.0080, 0.1007, 0.0109, 0.0527],\n",
      "        [0.1295, 0.0000, 0.0000, 0.0000, 0.1358, 0.0000, 0.0000, 0.0000, 0.1018,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4401, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1928, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "Transition matrix: tensor([[0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "def encode(s):\n",
    "  \"\"\"\n",
    "  Convert a string into a list of integers\n",
    "  \"\"\"\n",
    "  x = [alphabet.index(ss) for ss in s]\n",
    "  return x\n",
    "\n",
    "def decode(x):\n",
    "  \"\"\"\n",
    "  Convert list of ints to string\n",
    "  \"\"\"\n",
    "  s = \"\".join([alphabet[xx] for xx in x])\n",
    "  return s\n",
    "\n",
    "# Initialize the model\n",
    "model = HMM(M=len(alphabet), N=2)\n",
    "\n",
    "# Hard-wiring the parameters!\n",
    "# Let state 0 = consonant, state 1 = vowel\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False # needed to do lines below\n",
    "model.unnormalized_state_priors[0] = 0.    # Let's start with a consonant more frequently\n",
    "model.unnormalized_state_priors[1] = -0.5\n",
    "print(\"State priors:\", torch.nn.functional.softmax(model.unnormalized_state_priors, dim=0))\n",
    "\n",
    "# In state 0, only allow consonants; in state 1, only allow vowels\n",
    "vowel_indices = torch.tensor([alphabet.index(letter) for letter in \"aeiou\"])\n",
    "consonant_indices = torch.tensor([alphabet.index(letter) for letter in \"bcdfghjklmnpqrstvwxyz\"])\n",
    "model.emission_model.unnormalized_emission_matrix[0, vowel_indices] = -np.inf\n",
    "model.emission_model.unnormalized_emission_matrix[1, consonant_indices] = -np.inf\n",
    "print(\"Emission matrix:\", torch.nn.functional.softmax(model.emission_model.unnormalized_emission_matrix, dim=1))\n",
    "\n",
    "# Only allow vowel -> consonant and consonant -> vowel\n",
    "model.transition_model.unnormalized_transition_matrix[0,0] = -np.inf  # consonant -> consonant\n",
    "model.transition_model.unnormalized_transition_matrix[0,1] = 0.       # vowel -> consonant\n",
    "model.transition_model.unnormalized_transition_matrix[1,0] = 0.       # consonant -> vowel\n",
    "model.transition_model.unnormalized_transition_matrix[1,1] = -np.inf  # vowel -> vowel\n",
    "print(\"Transition matrix:\", torch.nn.functional.softmax(model.transition_model.unnormalized_transition_matrix, dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZiT3aWPlS7m",
    "outputId": "19e9d98a-3ad8-47ee-ea5f-0880d7b3149e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: elicu\n",
      "z: [1, 0, 1, 0, 1]\n",
      "x: pocob\n",
      "z: [0, 1, 0, 1, 0]\n",
      "x: fuxaq\n",
      "z: [0, 1, 0, 1, 0]\n",
      "x: gotox\n",
      "z: [0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Sample some outputs\n",
    "for _ in range(4):\n",
    "  sampled_x, sampled_z = model.sample(T=5)\n",
    "  print(\"x:\", decode(sampled_x))\n",
    "  print(\"z:\", sampled_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fw-QFyB-lebR"
   },
   "outputs": [],
   "source": [
    "def HMM_forward(self, x, T):\n",
    "  \"\"\"\n",
    "  x : IntTensor of shape (batch size, T_max)\n",
    "  T : IntTensor of shape (batch size)\n",
    "\n",
    "  Compute log p(x) for each example in the batch.\n",
    "  T = length of each example\n",
    "  \"\"\"\n",
    "  if self.is_cuda:\n",
    "  \tx = x.cuda()\n",
    "  \tT = T.cuda()\n",
    "\n",
    "  batch_size = x.shape[0]; T_max = x.shape[1]\n",
    "  log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n",
    "  log_alpha = torch.zeros(batch_size, T_max, self.N)\n",
    "  if self.is_cuda: log_alpha = log_alpha.cuda()\n",
    "\n",
    "  log_alpha[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n",
    "  for t in range(1, T_max):\n",
    "    log_alpha[:, t, :] = self.emission_model(x[:,t]) + self.transition_model(log_alpha[:, t-1, :])\n",
    "\n",
    "  # Select the sum for the final timestep (each x may have different length).\n",
    "  log_sums = log_alpha.logsumexp(dim=2)\n",
    "  log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n",
    "  return log_probs\n",
    "\n",
    "def emission_model_forward(self, x_t):\n",
    "  log_emission_matrix = torch.nn.functional.log_softmax(self.unnormalized_emission_matrix, dim=1)\n",
    "  out = log_emission_matrix[:, x_t].transpose(0,1)\n",
    "  return out\n",
    "\n",
    "def transition_model_forward(self, log_alpha):\n",
    "  \"\"\"\n",
    "  log_alpha : Tensor of shape (batch size, N)\n",
    "  Multiply previous timestep's alphas by transition matrix (in log domain)\n",
    "  \"\"\"\n",
    "  log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n",
    "\n",
    "  # Matrix multiplication in the log domain\n",
    "  out = log_domain_matmul(log_transition_matrix, log_alpha.transpose(0,1)).transpose(0,1)\n",
    "  return out\n",
    "\n",
    "def log_domain_matmul(log_A, log_B):\n",
    "\t\"\"\"\n",
    "\tlog_A : m x n\n",
    "\tlog_B : n x p\n",
    "\toutput : m x p matrix\n",
    "\n",
    "\tNormally, a matrix multiplication\n",
    "\tcomputes out_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
    "\n",
    "\tA log domain matrix multiplication\n",
    "\tcomputes out_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
    "\t\"\"\"\n",
    "\tm = log_A.shape[0]\n",
    "\tn = log_A.shape[1]\n",
    "\tp = log_B.shape[1]\n",
    "\n",
    "\t# log_A_expanded = torch.stack([log_A] * p, dim=2)\n",
    "\t# log_B_expanded = torch.stack([log_B] * m, dim=0)\n",
    "    # fix for PyTorch > 1.5 by egaznep on Github:\n",
    "\tlog_A_expanded = torch.reshape(log_A, (m,n,1))\n",
    "\tlog_B_expanded = torch.reshape(log_B, (1,n,p))\n",
    "\n",
    "\telementwise_sum = log_A_expanded + log_B_expanded\n",
    "\tout = torch.logsumexp(elementwise_sum, dim=1)\n",
    "\n",
    "\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_eUEpEnsljcx"
   },
   "outputs": [],
   "source": [
    "TransitionModel.forward = transition_model_forward\n",
    "EmissionModel.forward = emission_model_forward\n",
    "HMM.forward = HMM_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85uupGmelmj4",
    "outputId": "8ef50662-835b-4453-d19c-399be8b70d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.9049]])\n",
      "tensor([[-7.1966],\n",
      "        [   -inf]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.stack( [torch.tensor(encode(\"cat\"))] )\n",
    "T = torch.tensor([3])\n",
    "print(model.forward(x, T))\n",
    "\n",
    "x = torch.stack( [torch.tensor(encode(\"aba\")), torch.tensor(encode(\"abb\"))] )\n",
    "T = torch.tensor([3,3])\n",
    "print(model.forward(x, T))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k3gsporCluRR"
   },
   "outputs": [],
   "source": [
    "def viterbi(self, x, T):\n",
    "  \"\"\"\n",
    "  x : IntTensor of shape (batch size, T_max)\n",
    "  T : IntTensor of shape (batch size)\n",
    "  Find argmax_z log p(x|z) for each (x) in the batch.\n",
    "  \"\"\"\n",
    "  if self.is_cuda:\n",
    "    x = x.cuda()\n",
    "    T = T.cuda()\n",
    "\n",
    "  batch_size = x.shape[0]; T_max = x.shape[1]\n",
    "  log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n",
    "  log_delta = torch.zeros(batch_size, T_max, self.N).float()\n",
    "  psi = torch.zeros(batch_size, T_max, self.N).long()\n",
    "  if self.is_cuda:\n",
    "    log_delta = log_delta.cuda()\n",
    "    psi = psi.cuda()\n",
    "\n",
    "  log_delta[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n",
    "  for t in range(1, T_max):\n",
    "    max_val, argmax_val = self.transition_model.maxmul(log_delta[:, t-1, :])\n",
    "    log_delta[:, t, :] = self.emission_model(x[:,t]) + max_val\n",
    "    psi[:, t, :] = argmax_val\n",
    "\n",
    "  # Get the log probability of the best path\n",
    "  log_max = log_delta.max(dim=2)[0]\n",
    "  best_path_scores = torch.gather(log_max, 1, T.view(-1,1) - 1)\n",
    "\n",
    "  # This next part is a bit tricky to parallelize across the batch,\n",
    "  # so we will do it separately for each example.\n",
    "  z_star = []\n",
    "  for i in range(0, batch_size):\n",
    "    z_star_i = [ log_delta[i, T[i] - 1, :].max(dim=0)[1].item() ]\n",
    "    for t in range(T[i] - 1, 0, -1):\n",
    "      z_t = psi[i, t, z_star_i[0]].item()\n",
    "      z_star_i.insert(0, z_t)\n",
    "\n",
    "    z_star.append(z_star_i)\n",
    "\n",
    "  return z_star, best_path_scores # return both the best path and its log probability\n",
    "\n",
    "def transition_model_maxmul(self, log_alpha):\n",
    "  log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n",
    "\n",
    "  out1, out2 = maxmul(log_transition_matrix, log_alpha.transpose(0,1))\n",
    "  return out1.transpose(0,1), out2.transpose(0,1)\n",
    "\n",
    "def maxmul(log_A, log_B):\n",
    "\t\"\"\"\n",
    "\tlog_A : m x n\n",
    "\tlog_B : n x p\n",
    "\toutput : m x p matrix\n",
    "\n",
    "\tSimilar to the log domain matrix multiplication,\n",
    "\tthis computes out_{i,j} = max_k log_A_{i,k} + log_B_{k,j}\n",
    "\t\"\"\"\n",
    "\tm = log_A.shape[0]\n",
    "\tn = log_A.shape[1]\n",
    "\tp = log_B.shape[1]\n",
    "\n",
    "\tlog_A_expanded = torch.stack([log_A] * p, dim=2)\n",
    "\tlog_B_expanded = torch.stack([log_B] * m, dim=0)\n",
    "\n",
    "\telementwise_sum = log_A_expanded + log_B_expanded\n",
    "\tout1,out2 = torch.max(elementwise_sum, dim=1)\n",
    "\n",
    "\treturn out1,out2\n",
    "\n",
    "TransitionModel.maxmul = transition_model_maxmul\n",
    "HMM.viterbi = viterbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pN0Zh89Blxnz",
    "outputId": "e9c2397a-9598-4749-9d19-6d13c5836adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[1, 0, 1], [1, 0, 0]], tensor([[-7.1966],\n",
      "        [   -inf]]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.stack( [torch.tensor(encode(\"aba\")), torch.tensor(encode(\"abb\"))] )\n",
    "T = torch.tensor([3,3])\n",
    "print(model.viterbi(x, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBs9Wh3wl1Nr",
    "outputId": "3945e5e8-7f43-488e-c1d4-fa0e575e7626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.1966],\n",
      "        [   -inf]])\n",
      "tensor([[-7.1966],\n",
      "        [   -inf]])\n"
     ]
    }
   ],
   "source": [
    "print(model.forward(x, T))\n",
    "print(model.viterbi(x, T)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sizk7C0Il4Fu",
    "outputId": "e0a67c50-5611-4303-b282-8f76e0d873cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(3.4076)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "print(x.max(dim=0)[0])\n",
    "print(x.logsumexp(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oItfvXeel_HT"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, lines):\n",
    "    self.lines = lines # list of strings\n",
    "    collate = Collate() # function for generating a minibatch from strings\n",
    "    self.loader = torch.utils.data.DataLoader(self, batch_size=1024, num_workers=1, shuffle=True, collate_fn=collate)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.lines)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    line = self.lines[idx].lstrip(\" \").rstrip(\"\\n\").rstrip(\" \").rstrip(\"\\n\")\n",
    "    return line\n",
    "\n",
    "class Collate:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def __call__(self, batch):\n",
    "    \"\"\"\n",
    "    Returns a minibatch of strings, padded to have the same length.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    batch_size = len(batch)\n",
    "    for index in range(batch_size):\n",
    "      x_ = batch[index]\n",
    "\n",
    "      # convert letters to integers\n",
    "      x.append(encode(x_))\n",
    "\n",
    "    # pad all sequences with 0 to have same length\n",
    "    x_lengths = [len(x_) for x_ in x]\n",
    "    T = max(x_lengths)\n",
    "    for index in range(batch_size):\n",
    "      x[index] += [0] * (T - len(x[index]))\n",
    "      x[index] = torch.tensor(x[index])\n",
    "\n",
    "    # stack into single tensor\n",
    "    x = torch.stack(x)\n",
    "    x_lengths = torch.tensor(x_lengths)\n",
    "    return (x,x_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YGBvXcJmC-E",
    "outputId": "d8a95e76-61ed-44af-f60c-210367cbb27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-05 18:03:43--  https://raw.githubusercontent.com/lorenlugosch/pytorch_HMM/master/data/train/training.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2493109 (2.4M) [text/plain]\n",
      "Saving to: ‘training.txt’\n",
      "\n",
      "\r",
      "training.txt          0%[                    ]       0  --.-KB/s               \r",
      "training.txt        100%[===================>]   2.38M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-11-05 18:03:43 (31.8 MB/s) - ‘training.txt’ saved [2493109/2493109]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/lorenlugosch/pytorch_HMM/master/data/train/training.txt\n",
    "# If wget does not work, put the file in your current directory, or maybe use curl\n",
    "\n",
    "filename = \"training.txt\"\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "  lines = f.readlines() # each line of lines will have one word\n",
    "\n",
    "alphabet = list(Counter((\"\".join(lines))).keys())\n",
    "train_lines, valid_lines = train_test_split(lines, test_size=0.1, random_state=42)\n",
    "train_dataset = TextDataset(train_lines)\n",
    "valid_dataset = TextDataset(valid_lines)\n",
    "\n",
    "M = len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QGZiskiFmKZE"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm # for displaying progress bar\n",
    "\n",
    "class Trainer:\n",
    "  def __init__(self, model, lr):\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=0.00001)\n",
    "\n",
    "  def train(self, dataset):\n",
    "    train_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.train()\n",
    "    print_interval = 50\n",
    "    for idx, batch in enumerate(tqdm(dataset.loader)):\n",
    "      x,T = batch\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      log_probs = self.model(x,T)\n",
    "      loss = -log_probs.mean()\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.cpu().data.numpy().item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        print(\"loss:\", loss.item())\n",
    "        for _ in range(5):\n",
    "          sampled_x, sampled_z = self.model.sample()\n",
    "          print(decode(sampled_x))\n",
    "          print(sampled_z)\n",
    "    train_loss /= num_samples\n",
    "    return train_loss\n",
    "\n",
    "  def test(self, dataset):\n",
    "    test_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.eval()\n",
    "    print_interval = 50\n",
    "    for idx, batch in enumerate(dataset.loader):\n",
    "      x,T = batch\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      log_probs = self.model(x,T)\n",
    "      loss = -log_probs.mean()\n",
    "      test_loss += loss.cpu().data.numpy().item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        print(\"loss:\", loss.item())\n",
    "        sampled_x, sampled_z = self.model.sample()\n",
    "        print(decode(sampled_x))\n",
    "        print(sampled_z)\n",
    "    test_loss /= num_samples\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqcvdqKpmNcW",
    "outputId": "7b43304b-9979-44a3-96c6-79b5fd6d0e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch 1 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<02:50,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 38.897884368896484\n",
      "KUqzE-RDXU\n",
      "[62, 21, 12, 52, 51, 15, 53, 57, 37, 53]\n",
      "upfM\n",
      "cz\n",
      "\n",
      "z\n",
      "[5, 33, 13, 23, 28, 32, 43, 46, 2, 12]\n",
      "AGItnOyFmX\n",
      "[7, 61, 56, 61, 34, 5, 15, 50, 38, 56]\n",
      "ArPYQwdKSS\n",
      "[17, 19, 57, 53, 31, 54, 4, 19, 47, 48]\n",
      "CrSh-VpKoU\n",
      "[41, 37, 55, 49, 0, 56, 6, 31, 13, 52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:32<01:40,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33.372100830078125\n",
      "iCKqiyhbnu\n",
      "[46, 26, 15, 45, 46, 55, 15, 53, 46, 36]\n",
      "owkWXxNhZp\n",
      "[56, 23, 31, 28, 41, 48, 48, 54, 30, 51]\n",
      "wLpDnaVs\n",
      "p\n",
      "[33, 12, 5, 36, 55, 46, 26, 36, 31, 33]\n",
      "lqTdPnukfe\n",
      "[0, 43, 20, 4, 7, 33, 48, 37, 42, 12]\n",
      "dtnmtylmec\n",
      "[2, 50, 3, 59, 21, 55, 35, 59, 42, 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:04<01:07,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29.842239379882812\n",
      "eMenfmXtip\n",
      "[36, 9, 36, 6, 2, 59, 55, 22, 5, 5]\n",
      "IlmfdwqTsy\n",
      "[49, 49, 37, 42, 13, 5, 22, 42, 37, 56]\n",
      "crLWzeoUss\n",
      "[38, 27, 22, 48, 59, 12, 54, 14, 15, 0]\n",
      "j-am-iYlJK\n",
      "[9, 30, 35, 59, 47, 30, 24, 32, 43, 35]\n",
      "zltcCJroPt\n",
      "[24, 21, 56, 37, 42, 10, 17, 47, 30, 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:35<00:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28.22951889038086\n",
      "agugonDhst\n",
      "[30, 57, 20, 3, 41, 34, 56, 35, 12, 40]\n",
      "vumxrrZpie\n",
      "[4, 42, 59, 18, 37, 42, 53, 37, 42, 34]\n",
      "srYselEnrr\n",
      "[59, 27, 43, 56, 27, 35, 42, 34, 5, 46]\n",
      "nzpadiWryl\n",
      "[43, 36, 5, 30, 50, 8, 48, 37, 42, 47]\n",
      "milfjtnope\n",
      "[37, 42, 43, 30, 54, 21, 56, 42, 5, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:08<00:05,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.574800491333008\n",
      "ohondiowle\n",
      "[19, 35, 12, 55, 22, 21, 46, 30, 23, 58]\n",
      "ONrlesteri\n",
      "[11, 32, 18, 21, 46, 55, 22, 54, 21, 46]\n",
      "ufbixmepbr\n",
      "[1, 30, 37, 42, 12, 5, 12, 37, 47, 46]\n",
      "xeuatymnXr\n",
      "[59, 27, 21, 46, 15, 42, 34, 5, 12, 5]\n",
      "altidaWisi\n",
      "[59, 46, 15, 42, 31, 10, 27, 36, 56, 42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.63311767578125\n",
      "axenlanimo\n",
      "[30, 5, 36, 14, 15, 30, 56, 46, 5, 36]\n",
      "========= Results: epoch 1 of 10 =========\n",
      "train loss: 30.81| valid loss: 26.70\n",
      "\n",
      "========= Epoch 2 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<03:24,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 26.969579696655273\n",
      "Vidondaeil\n",
      "[35, 46, 5, 36, 14, 5, 30, 37, 42, 47]\n",
      "lcpenpnemu\n",
      "[1, 34, 5, 12, 5, 46, 34, 12, 5, 20]\n",
      "flaseejlli\n",
      "[24, 21, 30, 19, 36, 55, 3, 47, 21, 46]\n",
      "daGezyimxd\n",
      "[5, 46, 5, 36, 57, 43, 12, 5, 12, 5]\n",
      "rKachsleia\n",
      "[19, 47, 30, 50, 8, 26, 17, 8, 27, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:32<01:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25.53016471862793\n",
      "fauralentf\n",
      "[48, 30, 34, 5, 30, 47, 36, 55, 22, 21]\n",
      "dejmhBserv\n",
      "[5, 12, 56, 5, 8, 12, 5, 12, 34, 5]\n",
      "taTangreio\n",
      "[50, 8, 48, 30, 56, 22, 8, 26, 43, 0]\n",
      "sitermamQe\n",
      "[59, 27, 22, 12, 34, 5, 30, 5, 1, 27]\n",
      "gatistoslo\n",
      "[50, 30, 22, 42, 50, 15, 12, 34, 5, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:04<01:11,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25.344242095947266\n",
      "sstolomupc\n",
      "[56, 27, 22, 46, 15, 12, 5, 27, 22, 37]\n",
      "untMiesjns\n",
      "[36, 55, 36, 33, 21, 12, 56, 46, 55, 22]\n",
      "ghiteviari\n",
      "[33, 8, 46, 15, 12, 5, 46, 30, 22, 21]\n",
      "iskocaales\n",
      "[36, 14, 15, 12, 5, 30, 37, 47, 42, 50]\n",
      "bioncedabl\n",
      "[33, 21, 12, 34, 15, 12, 5, 30, 37, 47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:34<00:32,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.80217933654785\n",
      "teodmianta\n",
      "[22, 21, 12, 34, 5, 46, 30, 55, 22, 27]\n",
      "sylinnemil\n",
      "[24, 42, 47, 36, 55, 22, 12, 5, 46, 15]\n",
      "nanghocyra\n",
      "[5, 30, 55, 22, 8, 46, 50, 12, 34, 46]\n",
      "cenopaifth\n",
      "[24, 36, 14, 30, 5, 30, 36, 55, 22, 8]\n",
      "sibynyalel\n",
      "[20, 27, 5, 46, 15, 42, 30, 22, 12, 47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:06<00:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.50609588623047\n",
      "ganiscepei\n",
      "[33, 30, 5, 46, 14, 15, 27, 50, 8, 46]\n",
      "cftorthice\n",
      "[50, 30, 22, 12, 56, 50, 8, 46, 15, 46]\n",
      "phiallybyp\n",
      "[33, 8, 46, 30, 37, 47, 42, 5, 27, 22]\n",
      "akodalente\n",
      "[30, 22, 30, 15, 46, 5, 12, 55, 22, 12]\n",
      "selerigapo\n",
      "[24, 42, 47, 12, 56, 46, 15, 46, 50, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:10<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.808820724487305\n",
      "enutoidshi\n",
      "[36, 55, 27, 22, 12, 36, 34, 50, 8, 46]\n",
      "========= Results: epoch 2 of 10 =========\n",
      "train loss: 25.37| valid loss: 24.71\n",
      "\n",
      "========= Epoch 3 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<02:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 25.041990280151367\n",
      "fame\n",
      "ashit\n",
      "[33, 30, 59, 27, 22, 27, 50, 8, 27, 22]\n",
      "lerdorpali\n",
      "[5, 12, 34, 5, 12, 56, 50, 30, 47, 46]\n",
      "giiallirro\n",
      "[5, 46, 53, 30, 37, 47, 12, 34, 21, 30]\n",
      "segerperdo\n",
      "[5, 12, 5, 12, 34, 5, 12, 34, 5, 30]\n",
      "rsrotelort\n",
      "[5, 54, 21, 30, 22, 12, 47, 12, 56, 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:31<01:45,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.773218154907227\n",
      "intiztitea\n",
      "[36, 55, 22, 46, 15, 21, 46, 15, 12, 30]\n",
      "ntaurecisr\n",
      "[20, 22, 12, 27, 56, 27, 22, 46, 50, 8]\n",
      "bedetshemi\n",
      "[24, 36, 5, 27, 56, 50, 8, 12, 5, 46]\n",
      "blendidmaT\n",
      "[19, 47, 12, 55, 22, 46, 0, 5, 46, 25]\n",
      "Cintrateme\n",
      "[33, 36, 55, 22, 21, 30, 22, 12, 5, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:02<01:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.423091888427734\n",
      "migelallip\n",
      "[5, 46, 5, 12, 47, 30, 37, 47, 42, 50]\n",
      "blethupiuc\n",
      "[19, 47, 42, 22, 8, 42, 19, 36, 55, 15]\n",
      "bontewgurm\n",
      "[5, 30, 55, 22, 12, 34, 5, 12, 56, 59]\n",
      "stremiwpor\n",
      "[20, 22, 21, 12, 5, 46, 14, 5, 30, 34]\n",
      "masrabinnu\n",
      "[59, 27, 22, 21, 30, 37, 46, 14, 5, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:34<00:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.52507781982422\n",
      "cubitemafu\n",
      "[24, 36, 19, 27, 22, 12, 5, 27, 22, 12]\n",
      "niMifisthi\n",
      "[5, 46, 15, 46, 15, 46, 55, 22, 8, 46]\n",
      "rolustoctr\n",
      "[5, 12, 5, 12, 56, 22, 12, 55, 22, 21]\n",
      "debhesouto\n",
      "[5, 12, 5, 8, 12, 56, 30, 55, 22, 12]\n",
      "stelteetun\n",
      "[20, 22, 12, 56, 22, 12, 56, 22, 12, 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:05<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.06537628173828\n",
      "ustoannice\n",
      "[36, 56, 22, 12, 30, 55, 15, 27, 22, 12]\n",
      "tromatoffe\n",
      "[33, 21, 12, 5, 27, 22, 30, 45, 45, 12]\n",
      "pingerpani\n",
      "[33, 46, 14, 44, 12, 34, 50, 30, 55, 46]\n",
      "odylyblall\n",
      "[30, 15, 42, 47, 42, 37, 47, 27, 37, 47]\n",
      "cxm\n",
      "ntelti\n",
      "[24, 12, 5, 30, 55, 22, 12, 56, 22, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:09<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.159208297729492\n",
      "rativyemic\n",
      "[5, 27, 22, 46, 15, 27, 37, 59, 46, 15]\n",
      "========= Results: epoch 3 of 10 =========\n",
      "train loss: 24.41| valid loss: 24.26\n",
      "\n",
      "========= Epoch 4 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<03:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.876821517944336\n",
      "thpryutedp\n",
      "[33, 8, 33, 21, 46, 30, 22, 12, 34, 19]\n",
      "unkinmrede\n",
      "[36, 55, 22, 46, 14, 17, 21, 12, 5, 12]\n",
      "unnagotere\n",
      "[36, 55, 15, 30, 5, 30, 50, 12, 5, 12]\n",
      "vortiarion\n",
      "[5, 12, 56, 22, 46, 30, 5, 46, 30, 15]\n",
      "feodinkina\n",
      "[24, 25, 0, 5, 46, 55, 22, 46, 15, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:32<01:39,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.256649017333984\n",
      "brikyc\n",
      "esk\n",
      "[19, 21, 46, 15, 42, 50, 21, 12, 56, 38]\n",
      "dadlotshan\n",
      "[5, 30, 22, 47, 42, 50, 6, 8, 30, 55]\n",
      "semastobRp\n",
      "[24, 12, 5, 30, 56, 22, 30, 31, 20, 5]\n",
      "voyrimaete\n",
      "[5, 30, 42, 5, 46, 15, 27, 12, 22, 12]\n",
      "miponstlyt\n",
      "[5, 46, 50, 12, 56, 20, 26, 47, 42, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:03<01:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.937942504882812\n",
      "buteistiak\n",
      "[19, 27, 22, 12, 46, 20, 22, 46, 30, 15]\n",
      "sandsassha\n",
      "[24, 36, 55, 29, 21, 30, 56, 20, 8, 30]\n",
      "henbelingr\n",
      "[24, 36, 55, 5, 12, 21, 46, 14, 44, 21]\n",
      "acjAngefee\n",
      "[36, 55, 24, 36, 14, 44, 12, 45, 36, 58]\n",
      "unoamentin\n",
      "[36, 5, 12, 30, 5, 12, 56, 22, 46, 55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:34<00:35,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.866498947143555\n",
      "sablemeriv\n",
      "[24, 30, 37, 47, 12, 5, 12, 34, 46, 16]\n",
      "nodylliopa\n",
      "[5, 30, 34, 42, 37, 47, 46, 30, 5, 30]\n",
      "urnetoslif\n",
      "[36, 34, 5, 27, 22, 12, 56, 35, 36, 45]\n",
      "Oeostideni\n",
      "[36, 16, 12, 56, 22, 46, 15, 12, 5, 46]\n",
      "veretsimre\n",
      "[16, 12, 5, 12, 56, 20, 36, 34, 5, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:06<00:04,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.860408782958984\n",
      "altestryst\n",
      "[36, 55, 22, 12, 56, 22, 21, 42, 56, 22]\n",
      "illacaleme\n",
      "[36, 37, 47, 27, 22, 30, 5, 12, 5, 12]\n",
      "hogytuical\n",
      "[24, 30, 44, 12, 50, 8, 46, 15, 27, 37]\n",
      "iqkedrinep\n",
      "[36, 6, 53, 12, 62, 21, 46, 15, 12, 22]\n",
      "Perficeffa\n",
      "[24, 12, 34, 19, 46, 15, 12, 45, 45, 36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:10<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.88800811767578\n",
      "uxaivurica\n",
      "[36, 55, 30, 46, 15, 27, 21, 46, 15, 27]\n",
      "========= Results: epoch 4 of 10 =========\n",
      "train loss: 24.05| valid loss: 23.95\n",
      "\n",
      "========= Epoch 5 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<02:48,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.37877655029297\n",
      "landiyseme\n",
      "[24, 36, 55, 29, 46, 12, 21, 12, 5, 12]\n",
      "entesmulio\n",
      "[36, 55, 22, 12, 56, 59, 27, 37, 46, 30]\n",
      "alWpedassy\n",
      "[30, 23, 42, 50, 12, 5, 30, 56, 20, 42]\n",
      "stocfumive\n",
      "[20, 22, 30, 55, 24, 36, 34, 46, 5, 12]\n",
      "linyllaist\n",
      "[5, 46, 15, 42, 37, 47, 30, 46, 20, 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:33<01:45,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.88699722290039\n",
      "syrssiapin\n",
      "[24, 42, 56, 20, 22, 46, 30, 5, 46, 14]\n",
      "phnifarech\n",
      "[50, 8, 5, 46, 15, 27, 21, 12, 50, 8]\n",
      "fycyiohgan\n",
      "[24, 42, 15, 42, 46, 30, 14, 44, 36, 55]\n",
      "trosanotup\n",
      "[33, 21, 30, 22, 30, 5, 12, 5, 12, 56]\n",
      "chelergoco\n",
      "[50, 8, 42, 47, 12, 34, 5, 30, 56, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:06<01:23,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.1594295501709\n",
      "sphallytho\n",
      "[20, 50, 8, 27, 37, 47, 42, 50, 8, 30]\n",
      "henomvblen\n",
      "[24, 12, 56, 0, 5, 27, 37, 47, 12, 5]\n",
      "phomingron\n",
      "[50, 8, 30, 5, 46, 14, 44, 21, 36, 55]\n",
      "scowehyned\n",
      "[20, 22, 30, 5, 12, 8, 42, 5, 12, 29]\n",
      "tozlurpric\n",
      "[33, 30, 37, 47, 12, 34, 19, 21, 46, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:39<00:36,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.34781837463379\n",
      "umgrycadec\n",
      "[36, 34, 19, 21, 42, 50, 30, 5, 12, 55]\n",
      "riponpesti\n",
      "[5, 46, 50, 30, 55, 19, 12, 56, 22, 46]\n",
      "efeisnoyec\n",
      "[36, 45, 12, 46, 0, 5, 30, 5, 12, 22]\n",
      "mypocuenti\n",
      "[24, 42, 50, 30, 50, 8, 12, 55, 22, 46]\n",
      "partisphis\n",
      "[33, 30, 56, 22, 46, 20, 50, 8, 46, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:10<00:04,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.738645553588867\n",
      "Aftedrisum\n",
      "[36, 45, 22, 12, 29, 21, 46, 20, 0, 5]\n",
      "gomawsufed\n",
      "[50, 30, 5, 27, 55, 20, 28, 19, 12, 34]\n",
      "medanedioc\n",
      "[59, 36, 5, 30, 5, 12, 5, 46, 30, 50]\n",
      "trothonera\n",
      "[33, 21, 30, 22, 8, 30, 5, 12, 21, 30]\n",
      "nyntechkei\n",
      "[5, 27, 55, 22, 12, 50, 8, 53, 12, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:14<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.8298397064209\n",
      "eutisptomg\n",
      "[36, 55, 22, 46, 20, 50, 22, 30, 7, 44]\n",
      "========= Results: epoch 5 of 10 =========\n",
      "train loss: 23.84| valid loss: 23.80\n",
      "\n",
      "========= Epoch 6 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<02:59,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.86598777770996\n",
      "cruspolori\n",
      "[33, 21, 36, 55, 50, 30, 47, 12, 21, 46]\n",
      "plallnstle\n",
      "[19, 47, 27, 37, 47, 12, 56, 22, 47, 12]\n",
      "medoustico\n",
      "[5, 12, 5, 30, 54, 20, 22, 46, 15, 12]\n",
      "armkyxdibl\n",
      "[36, 34, 59, 15, 42, 34, 29, 46, 37, 47]\n",
      "amlumalitu\n",
      "[30, 34, 47, 12, 5, 27, 37, 46, 50, 36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:31<01:46,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.67974281311035\n",
      "armuecelys\n",
      "[36, 34, 59, 36, 31, 19, 30, 47, 42, 56]\n",
      "poustalanc\n",
      "[5, 30, 54, 20, 22, 30, 37, 27, 55, 15]\n",
      "irgivuogyr\n",
      "[36, 34, 5, 46, 16, 12, 30, 44, 42, 34]\n",
      "hertemapef\n",
      "[24, 36, 34, 50, 12, 5, 30, 50, 12, 51]\n",
      "Fenigherse\n",
      "[24, 12, 5, 46, 6, 8, 12, 56, 20, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:02<01:04,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.82386016845703\n",
      "contogedlo\n",
      "[24, 36, 55, 22, 0, 5, 12, 23, 47, 30]\n",
      "padosthamo\n",
      "[33, 30, 5, 30, 56, 22, 8, 30, 5, 30]\n",
      "nistesotin\n",
      "[5, 46, 20, 22, 12, 56, 12, 22, 46, 15]\n",
      "dergvatseb\n",
      "[29, 12, 56, 0, 5, 30, 56, 20, 12, 5]\n",
      "Monatracta\n",
      "[24, 36, 5, 27, 22, 21, 30, 55, 22, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:35<00:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.68906593322754\n",
      "tintellewi\n",
      "[24, 36, 55, 22, 12, 37, 47, 12, 34, 46]\n",
      "peIantogen\n",
      "[19, 12, 5, 27, 55, 22, 30, 44, 12, 5]\n",
      "rsanoryger\n",
      "[56, 20, 30, 5, 30, 34, 42, 44, 12, 34]\n",
      "motesthlet\n",
      "[24, 30, 22, 12, 56, 50, 8, 47, 12, 50]\n",
      "pophfluchi\n",
      "[19, 30, 50, 8, 57, 47, 42, 50, 8, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:07<00:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.41640281677246\n",
      "antingliol\n",
      "[36, 55, 22, 46, 14, 44, 47, 46, 30, 47]\n",
      "wardaestmu\n",
      "[33, 30, 34, 5, 27, 12, 56, 22, 59, 36]\n",
      "diqhitotak\n",
      "[29, 46, 6, 8, 46, 15, 30, 15, 27, 53]\n",
      "hersauslea\n",
      "[24, 12, 34, 5, 30, 54, 20, 47, 12, 27]\n",
      "oringigust\n",
      "[36, 34, 46, 14, 44, 46, 15, 27, 56, 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:11<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.003253936767578\n",
      "cogbizetem\n",
      "[50, 30, 0, 5, 46, 15, 27, 22, 12, 5]\n",
      "========= Results: epoch 6 of 10 =========\n",
      "train loss: 23.70| valid loss: 23.69\n",
      "\n",
      "========= Epoch 7 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:01<03:27,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.372812271118164\n",
      "lochideded\n",
      "[35, 30, 50, 8, 46, 15, 12, 5, 12, 5]\n",
      "santuqhand\n",
      "[20, 36, 55, 22, 54, 6, 8, 27, 55, 29]\n",
      "coneselsto\n",
      "[24, 30, 5, 12, 56, 12, 55, 20, 22, 30]\n",
      "ioshucergu\n",
      "[36, 55, 20, 8, 12, 50, 12, 34, 44, 12]\n",
      "ulkodapopo\n",
      "[36, 55, 22, 30, 5, 30, 50, 30, 50, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:32<01:39,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.73843002319336\n",
      "mosiouscit\n",
      "[24, 12, 56, 46, 30, 54, 20, 22, 46, 50]\n",
      "heschanMie\n",
      "[24, 12, 56, 50, 8, 27, 55, 24, 46, 30]\n",
      "tharoculiv\n",
      "[33, 8, 30, 5, 30, 50, 41, 47, 42, 5]\n",
      "wrocetivec\n",
      "[33, 21, 30, 50, 12, 22, 46, 16, 12, 55]\n",
      "Barogrisli\n",
      "[24, 30, 21, 30, 44, 21, 46, 0, 5, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:04<01:08,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.490846633911133\n",
      "uflecsatom\n",
      "[36, 45, 45, 12, 56, 20, 27, 22, 30, 5]\n",
      "pratopento\n",
      "[33, 21, 27, 22, 0, 5, 12, 55, 22, 30]\n",
      "pritonocss\n",
      "[33, 35, 46, 22, 30, 55, 30, 15, 56, 20]\n",
      "lergerpelu\n",
      "[24, 12, 34, 44, 12, 34, 19, 12, 21, 12]\n",
      "Propidablu\n",
      "[33, 21, 30, 5, 46, 15, 27, 37, 47, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:36<00:34,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.571678161621094\n",
      "feddleovot\n",
      "[24, 12, 23, 23, 47, 12, 30, 5, 30, 55]\n",
      "icfarmirtt\n",
      "[36, 55, 11, 30, 34, 5, 27, 55, 50, 22]\n",
      "tolitoraly\n",
      "[33, 30, 5, 42, 50, 30, 34, 27, 37, 42]\n",
      "Fhioaheadl\n",
      "[33, 8, 46, 30, 49, 58, 12, 27, 37, 47]\n",
      "aftlernomi\n",
      "[36, 45, 22, 47, 12, 34, 5, 30, 5, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:08<00:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.48708152770996\n",
      "ceqlolator\n",
      "[24, 12, 50, 35, 36, 47, 27, 22, 12, 56]\n",
      "holiarelul\n",
      "[24, 30, 37, 46, 27, 21, 12, 37, 41, 47]\n",
      "autisphess\n",
      "[36, 55, 22, 46, 20, 50, 8, 12, 56, 22]\n",
      "fertushend\n",
      "[24, 12, 56, 50, 54, 20, 8, 12, 55, 24]\n",
      "Hungvaengr\n",
      "[24, 36, 14, 44, 5, 27, 12, 14, 44, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.332876205444336\n",
      "staurament\n",
      "[20, 22, 30, 54, 21, 30, 5, 12, 55, 22]\n",
      "========= Results: epoch 7 of 10 =========\n",
      "train loss: 23.60| valid loss: 23.60\n",
      "\n",
      "========= Epoch 8 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:01<03:27,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.6558837890625\n",
      "novewmimol\n",
      "[24, 36, 16, 12, 48, 59, 36, 5, 30, 5]\n",
      "firessctel\n",
      "[45, 46, 5, 12, 56, 20, 50, 22, 36, 56]\n",
      "satetisben\n",
      "[20, 27, 22, 12, 56, 46, 20, 19, 12, 5]\n",
      "onysnetica\n",
      "[36, 5, 42, 20, 43, 12, 22, 46, 15, 27]\n",
      "lingedonea\n",
      "[5, 46, 14, 44, 12, 23, 0, 5, 12, 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:33<01:42,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.625843048095703\n",
      "satrodicue\n",
      "[20, 27, 22, 21, 30, 5, 46, 50, 8, 12]\n",
      "venNunuzec\n",
      "[24, 12, 55, 24, 36, 55, 36, 16, 12, 50]\n",
      "untaacgous\n",
      "[36, 55, 22, 30, 36, 55, 44, 30, 54, 20]\n",
      "Veacusteys\n",
      "[24, 12, 30, 50, 54, 20, 22, 12, 42, 20]\n",
      "Airistoscs\n",
      "[24, 36, 34, 46, 20, 22, 46, 20, 22, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:05<01:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.376598358154297\n",
      "crieganusu\n",
      "[33, 21, 46, 30, 44, 30, 5, 54, 20, 28]\n",
      "dicytKhern\n",
      "[29, 46, 15, 42, 50, 60, 8, 12, 34, 5]\n",
      "hysenorysl\n",
      "[61, 42, 5, 12, 5, 30, 34, 46, 20, 35]\n",
      "tesilcisst\n",
      "[33, 30, 20, 46, 56, 22, 46, 56, 20, 22]\n",
      "namemeefic\n",
      "[24, 30, 5, 12, 34, 12, 34, 45, 46, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:37<00:40,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.60538673400879\n",
      "miyrstelyl\n",
      "[24, 46, 12, 56, 20, 22, 12, 47, 42, 47]\n",
      "cosymmolis\n",
      "[15, 30, 20, 28, 31, 59, 0, 5, 46, 20]\n",
      "forefuleda\n",
      "[24, 30, 34, 12, 11, 41, 47, 12, 23, 0]\n",
      "picitenepo\n",
      "[19, 46, 15, 46, 22, 12, 43, 12, 5, 30]\n",
      "rabemerydr\n",
      "[24, 30, 19, 12, 5, 12, 34, 42, 62, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:08<00:04,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.57352066040039\n",
      "remastebof\n",
      "[24, 36, 5, 30, 56, 22, 12, 5, 30, 29]\n",
      "vatyclisto\n",
      "[24, 30, 61, 42, 50, 35, 46, 20, 50, 30]\n",
      "ragsapuivi\n",
      "[24, 30, 44, 5, 30, 50, 8, 46, 16, 12]\n",
      "pronfopele\n",
      "[19, 21, 30, 5, 29, 30, 50, 12, 47, 12]\n",
      "sbrionolep\n",
      "[20, 19, 21, 46, 0, 5, 30, 47, 12, 56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.348670959472656\n",
      "cepskoAnhl\n",
      "[24, 12, 56, 20, 22, 30, 36, 5, 8, 5]\n",
      "========= Results: epoch 8 of 10 =========\n",
      "train loss: 23.51| valid loss: 23.50\n",
      "\n",
      "========= Epoch 9 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<02:31,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.08064842224121\n",
      "Liededadar\n",
      "[24, 30, 49, 29, 12, 23, 0, 5, 30, 34]\n",
      "pofferturo\n",
      "[33, 30, 45, 45, 12, 34, 22, 8, 21, 30]\n",
      "Pabimilino\n",
      "[33, 27, 37, 46, 5, 46, 15, 46, 5, 30]\n",
      "Locercanen\n",
      "[24, 30, 50, 12, 56, 50, 30, 5, 12, 5]\n",
      "stonescful\n",
      "[20, 22, 30, 5, 12, 20, 50, 51, 41, 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:32<01:45,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.57033348083496\n",
      "renoorened\n",
      "[24, 12, 5, 30, 36, 5, 12, 43, 12, 23]\n",
      "Caomutogia\n",
      "[33, 30, 36, 31, 41, 22, 0, 5, 46, 27]\n",
      "qhlerphter\n",
      "[6, 8, 47, 12, 34, 50, 8, 22, 12, 34]\n",
      "qhedlacnea\n",
      "[6, 8, 12, 23, 47, 27, 22, 43, 12, 30]\n",
      "torobusion\n",
      "[24, 30, 34, 46, 0, 54, 20, 46, 30, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:04<01:13,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.241405487060547\n",
      "goglerexib\n",
      "[33, 30, 44, 47, 12, 21, 12, 5, 46, 37]\n",
      "foonillyla\n",
      "[11, 30, 0, 5, 46, 37, 47, 42, 35, 30]\n",
      "larilerall\n",
      "[35, 30, 56, 46, 47, 12, 34, 27, 37, 47]\n",
      "drefledian\n",
      "[33, 21, 12, 4, 47, 12, 5, 46, 27, 14]\n",
      "tophovanob\n",
      "[33, 30, 50, 8, 0, 5, 30, 5, 30, 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:36<00:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.21142578125\n",
      "merotastro\n",
      "[24, 12, 34, 30, 50, 30, 20, 22, 21, 30]\n",
      "orenanicep\n",
      "[36, 34, 12, 55, 0, 5, 46, 15, 27, 19]\n",
      "Eokogristh\n",
      "[24, 30, 35, 30, 44, 21, 46, 20, 22, 21]\n",
      "rapessumma\n",
      "[24, 30, 50, 12, 56, 20, 28, 31, 59, 30]\n",
      "ariculytap\n",
      "[36, 34, 46, 15, 41, 47, 42, 50, 30, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:09<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.4835147857666\n",
      "socphausle\n",
      "[24, 36, 55, 50, 8, 30, 54, 20, 47, 12]\n",
      "jamacenimp\n",
      "[24, 30, 59, 30, 50, 36, 5, 46, 31, 19]\n",
      "befrorbuld\n",
      "[19, 12, 57, 21, 30, 34, 40, 41, 37, 29]\n",
      "Dondaffych\n",
      "[24, 30, 55, 29, 30, 45, 45, 42, 50, 8]\n",
      "karoiustuo\n",
      "[38, 27, 34, 30, 49, 54, 20, 50, 8, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:12<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.426456451416016\n",
      "Lonaterust\n",
      "[24, 30, 5, 27, 22, 12, 21, 54, 20, 22]\n",
      "========= Results: epoch 9 of 10 =========\n",
      "train loss: 23.43| valid loss: 23.44\n",
      "\n",
      "========= Epoch 10 of 10 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/208 [00:00<03:01,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24.027624130249023\n",
      "merctantfa\n",
      "[59, 12, 34, 50, 22, 27, 55, 22, 51, 27]\n",
      "togrocaces\n",
      "[33, 30, 44, 21, 30, 50, 27, 22, 12, 56]\n",
      "mesdkwfule\n",
      "[24, 36, 55, 15, 38, 48, 51, 41, 35, 36]\n",
      "fraritaria\n",
      "[19, 21, 30, 34, 46, 22, 30, 34, 46, 27]\n",
      "unillalyss\n",
      "[36, 5, 46, 37, 47, 27, 47, 42, 56, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 51/208 [00:31<01:45,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.121946334838867\n",
      "mornunphmi\n",
      "[24, 30, 34, 5, 36, 55, 50, 8, 5, 46]\n",
      "imessalter\n",
      "[36, 31, 12, 56, 20, 36, 55, 22, 12, 34]\n",
      "idnessosis\n",
      "[36, 23, 43, 12, 56, 22, 30, 56, 46, 20]\n",
      "rotdistove\n",
      "[24, 30, 55, 29, 46, 20, 22, 30, 16, 12]\n",
      "melialalif\n",
      "[24, 12, 47, 46, 30, 37, 27, 37, 46, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 101/208 [01:03<01:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.139862060546875\n",
      "blymarsoit\n",
      "[19, 47, 42, 5, 27, 56, 20, 30, 49, 22]\n",
      "kecenskedw\n",
      "[24, 12, 22, 12, 55, 20, 53, 12, 23, 48]\n",
      "gericnemio\n",
      "[33, 30, 34, 46, 22, 43, 12, 5, 46, 0]\n",
      "sqhounsypn\n",
      "[20, 6, 8, 30, 36, 55, 20, 28, 31, 5]\n",
      "chicessted\n",
      "[33, 8, 46, 15, 12, 56, 20, 22, 12, 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 151/208 [01:36<00:36,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.20691680908203\n",
      "Moaeutiqur\n",
      "[24, 32, 30, 36, 55, 22, 46, 6, 8, 21]\n",
      "populomapu\n",
      "[33, 36, 50, 41, 35, 30, 59, 30, 19, 36]\n",
      "ontatrarmi\n",
      "[36, 55, 15, 27, 22, 21, 30, 34, 5, 46]\n",
      "sotonibisi\n",
      "[24, 30, 55, 0, 5, 46, 37, 30, 20, 46]\n",
      "muntegesse\n",
      "[24, 36, 55, 22, 30, 44, 12, 56, 20, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 201/208 [02:08<00:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.188507080078125\n",
      "rimarciSte\n",
      "[24, 30, 59, 30, 34, 50, 46, 20, 22, 30]\n",
      "uutarnogli\n",
      "[36, 55, 22, 30, 34, 5, 30, 44, 47, 46]\n",
      "faussneral\n",
      "[24, 30, 54, 56, 20, 43, 12, 34, 27, 37]\n",
      "lismaplers\n",
      "[35, 30, 20, 59, 30, 19, 47, 12, 56, 20]\n",
      "entinuloni\n",
      "[36, 55, 22, 46, 5, 41, 35, 30, 5, 46]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [02:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23.3612060546875\n",
      "nansingymu\n",
      "[24, 36, 55, 20, 46, 14, 44, 42, 59, 12]\n",
      "========= Results: epoch 10 of 10 =========\n",
      "train loss: 23.38| valid loss: 23.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = HMM(N=64, M=M)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "trainer = Trainer(model, lr=0.01)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        print(\"========= Epoch %d of %d =========\" % (epoch+1, num_epochs))\n",
    "        train_loss = trainer.train(train_dataset)\n",
    "        valid_loss = trainer.test(valid_dataset)\n",
    "\n",
    "        print(\"========= Results: epoch %d of %d =========\" % (epoch+1, num_epochs))\n",
    "        print(\"train loss: %.2f| valid loss: %.2f\\n\" % (train_loss, valid_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYq1OiBemSw-",
    "outputId": "28a56ace-0170-4c83-ce7c-22bd9f761708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[6, 8, 30, 50, 38]], tensor([[-16.1840]], grad_fn=<GatherBackward0>))\n",
      "([[6, 8, 46, 15, 38]], tensor([[-14.7257]], grad_fn=<GatherBackward0>))\n",
      "([[33, 28, 34, 50, 38]], tensor([[-21.5828]], grad_fn=<GatherBackward0>))\n",
      "([[6, 8, 46, 15, 38]], tensor([[-21.3148]], grad_fn=<GatherBackward0>))\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(encode(\"quack\")).unsqueeze(0)\n",
    "T = torch.tensor([5])\n",
    "print(model.viterbi(x,T))\n",
    "\n",
    "x = torch.tensor(encode(\"quick\")).unsqueeze(0)\n",
    "T = torch.tensor([5])\n",
    "print(model.viterbi(x,T))\n",
    "\n",
    "x = torch.tensor(encode(\"qurck\")).unsqueeze(0)\n",
    "T = torch.tensor([5])\n",
    "print(model.viterbi(x,T)) # should have lower probability---in English only vowels follow \"qu\"\n",
    "\n",
    "x = torch.tensor(encode(\"qiick\")).unsqueeze(0)\n",
    "T = torch.tensor([5])\n",
    "print(model.viterbi(x,T)) # should have lower probability---in English only \"u\" follows \"q\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
